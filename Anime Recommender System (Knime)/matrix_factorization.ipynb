{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "This is one of the most used ways of creating a recommendation system.\n",
    "\n",
    "The way the model works is by finding some latent features of users and films and then multiplying them together.\n",
    "The result should be intended as the model prediction for a given user on any given film.\n",
    "\n",
    "The ideal matrix would probably look something like:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "10  & 8 & 2 & 7 & 5\\\\\n",
    "1 & 7 & 8 & 9 & 5\\\\\n",
    "1 & 3 & 5 & 7 & 2\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where the users are represented one for each row and on the columns we have the films.\n",
    "\n",
    "However, this does not happen quite as frequently in real life as usually people rate very few movies, and the chance of finding different users who rated the same movie is not very high. \n",
    "This results in very sparse matrices where the $\\text{No}$ means the user did not review the film:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "10  & \\text{No} & \\text{No} & \\text{No} & 1\\\\\n",
    "\\text{No} & \\text{No} & 8 & \\text{No} & \\text{No}\\\\\n",
    "\\text{No} & \\text{No} & 5 & 7 & 2\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Ideally, we want to reduce the sparsity as much as possible.\n",
    "We can try to do this by always using all the movies rated by a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# Reproducibility -> Also ensures same train / validation / test split every time\n",
    "t.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset uses the file \"rating_complete.csv\" taken from https://www.kaggle.com/datasets/hernan4444/anime-recommendation-database-2020\n",
    "\n",
    "A small sample of the dataset is added to the git repository for quick tinkering.\n",
    "\n",
    "The examples are going to be matrices of size $m$ rows and $n$ columns.\n",
    "\n",
    "Alongside the matrix for a given index we are also going to provide a list of users (where the user at position $i$ is the rater of the $i$th row in the matrix) and a list of the anime ids which in turns is relative to the columns.\n",
    "The model is supposed to learn anime features and user preferences all by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv from: /home/andreacacioli/Documents/github/MachineLearning/Anime Recommender System (Knime)/rating_complete.csv\n",
      "torch.Size([288, 265])\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AnimeReviewsDataset(Dataset):\n",
    "    def __init__(self, path, splits) -> None:\n",
    "        print(f\"Reading csv from: {path}\")\n",
    "        self.dataset_name = path.split('/')[-1]\n",
    "        self.df = read_csv(path)\n",
    "        self.df = self.df.sample(frac=1, random_state=0) # Adding random state for reproducibility and dataset separation\n",
    "        self.length = self.df.shape[0] // splits\n",
    "        self.ratings = self.df['rating'].to_list()\n",
    "        self.users = self.df['user_id'].unique()\n",
    "        self.animes = self.df['anime_id'].unique()\n",
    "        self.user_conversion_table = {self.users[i]: i for i in range(len(self.users))}\n",
    "        self.anime_conversion_table = {self.animes[i]: i for i in range(len(self.animes))}\n",
    "\n",
    "    def convert_user_from_model_to_csv(self, users):\n",
    "        return [self.users[u] for u in users]\n",
    "\n",
    "    def convert_anime_from_model_to_csv(self, animes):\n",
    "        return [self.animes[a] for a in animes]\n",
    "\n",
    "\n",
    "    def convert_user_from_csv_to_model(self, users):\n",
    "        return [self.user_conversion_table[u] for u in users]\n",
    "\n",
    "    def convert_anime_from_csv_to_model(self, animes):\n",
    "        return [self.anime_conversion_table[a] for a in animes]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0] // self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        df = self.df[index * self.length: index * self.length + self.length]\n",
    "        table = df.pivot_table(values='rating', index='user_id',columns='anime_id', fill_value = 0)\n",
    "        users = table.index.array.tolist()\n",
    "        users = self.convert_user_from_csv_to_model(users)\n",
    "        animes = table.columns.array.tolist()\n",
    "        animes = self.convert_anime_from_csv_to_model(animes)\n",
    "\n",
    "        return t.Tensor(users).long(), t.Tensor(animes).long(), t.Tensor(table.to_numpy()).long()\n",
    "\n",
    "\n",
    "splits = 200000\n",
    "dataset = AnimeReviewsDataset(\"/home/andreacacioli/Documents/github/MachineLearning/Anime Recommender System (Knime)/rating_complete.csv\", splits)\n",
    "print(dataset.__getitem__(100)[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data distribution visualization\n",
    "\n",
    "We now plot the data to see how the ratings are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = dataset.ratings\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(x, bins=10, edgecolor='black') \n",
    "plt.title(\"Rating Distribution\") \n",
    "plt.xlabel(\"rating\") \n",
    "plt.ylabel(\"Frequency\") \n",
    "plt.grid(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the dataset\n",
    "\n",
    "We split the dataset into training, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140081\n",
      "40023\n",
      "20011\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "train_dataset, test_dataset, validation_dataset = random_split(dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, shuffle=True)\n",
    "\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))\n",
    "print(len(validation_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "\n",
    "The model attempts to learn the features of the animes and of the users by embedding them using simple embedding tables.\n",
    "This also means that the model size highly depends on the number of users and on the number of animes in the dataset.\n",
    "\n",
    "A different method could also be attempted where the embedding is done without using embedding tables.\n",
    "\n",
    "Embedding Maximum Norm\n",
    "---\n",
    "\n",
    "Since the model uses a Sigmoid function, whenever the input values are too high or too low, the gradient becomes close to zero, making it impossible for the model to learn anything.\n",
    "This is called the **vanishing gradient problem**.\n",
    "\n",
    "To solve this we opt to setting a maximum value for the norm of each embedding vector.\n",
    "Think of a matrix of users $U$\n",
    "$$\n",
    "U = \\begin{bmatrix}\n",
    "    U_{1,0} & ... & U_{1,emb\\_size} \\\\\n",
    "    U_{2,0} & ... & U_{1,emb\\_size} \\\\\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And think of a matrix of Animes $A$\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "    A_{1,0} & ... & A_{1,emb\\_size} \\\\\n",
    "    A_{2,0} & ... & A_{1,emb\\_size} \\\\\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then the model performs matrix multiplication calculating $M = UA^T$.\n",
    "To make sure that the resulting matrix at any given position is smaller than a threshold $t$, over which the gradient would vanish, we need to consider that at any position $i,j$ of the matrix $M = UA^T$ the value is\n",
    "\n",
    "$$\n",
    "M_{i,j} = \\sum_{k = 0}^{k < emb\\_size}{U_{i,k}A_{j,k}}\n",
    "$$\n",
    "\n",
    "We can ensure this by forcing the inf norm (biggest value) of any given embedding vector to be at most $n$.\n",
    "\n",
    "This means that in the worst case (the one where every value of the embedding is $n$ for both the user and the anime) the value in a given cell $c$ of the resulting matrix is\n",
    "\n",
    "$$\n",
    "c = emb\\_size \\cdot n^2\n",
    "$$\n",
    "\n",
    "Forcing $c$ to be less than $t$ we get and solving for the norm $n$:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}   \n",
    "\n",
    "        c & \\le t \\\\\n",
    "        emb\\_size \\cdot n^2 & \\le t \\\\\n",
    "        n^2 & \\le \\frac{t}{emb\\_size} \\\\\n",
    "        n & \\le \\sqrt{\\frac{t}{emb\\_size}}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334.78M\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class MatrixFactorizationModel(t.nn.Module):\n",
    "    def __init__(self, emb_size, device) -> None:\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.device = device\n",
    "        self.user_embedder = t.nn.Embedding(len(dataset.users), emb_size).to(device)\n",
    "        self.anime_embedder = t.nn.Embedding(len(dataset.animes), emb_size).to(device)\n",
    "        thresh = 1\n",
    "        max_norm = thresh / math.sqrt(emb_size)\n",
    "        t.nn.init.uniform_(self.user_embedder.weight, -max_norm, max_norm)\n",
    "        t.nn.init.uniform_(self.anime_embedder.weight, -max_norm, max_norm)\n",
    "\n",
    "    def forward(self, users, animes):\n",
    "        users, animes = users.to(self.device), animes.to(self.device)\n",
    "        # Users is [U, emb_size]\n",
    "        users = self.user_embedder(users)\n",
    "        # Users is [A, emb_size]\n",
    "        animes = self.anime_embedder(animes)\n",
    "        pred = users @ animes.T\n",
    "\n",
    "        #Sigmoid to get results in given range\n",
    "        pred = t.nn.functional.sigmoid(pred)\n",
    "        pred = pred * 9\n",
    "        pred = pred + 1\n",
    "        return pred\n",
    "\n",
    "    def size(self):\n",
    "        def human_format(num):\n",
    "            magnitude = 0\n",
    "            while abs(num) >= 1000:\n",
    "                magnitude += 1\n",
    "                num /= 1000.0\n",
    "            # add more suffixes if you need them\n",
    "            return \"%.2f%s\" % (num, [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"][magnitude])\n",
    "\n",
    "        return human_format(sum(p.numel() for p in self.parameters()))\n",
    "\n",
    "\n",
    "model = MatrixFactorizationModel(emb_size=1024, device=device)\n",
    "print(model.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a generic step\n",
    "\n",
    "We perform this step regardless of the model, optimizer, or the phase we are in (training / test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_step(model, loss_fn, users, anime, target):\n",
    "    target = target.to(device=device).type(t.float32)\n",
    "    target = target.squeeze()\n",
    "    users = users.squeeze()\n",
    "    anime = anime.squeeze()\n",
    "    \n",
    "    x = model(users, anime)\n",
    "    #Only getting real ratings (range [1-10])\n",
    "    mask = target != 0\n",
    "    target = target[mask]\n",
    "    x = x[mask]\n",
    "    loss = loss_fn(x, target)\n",
    "    return loss, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Steps\n",
    "\n",
    "Here we check if everything is set up correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Norm: 0.5894988551152341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.4148, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = t.nn.MSELoss()\n",
    "learning_rate = 0.0001\n",
    "optimizer = t.optim.Adam(model.parameters(), learning_rate)\n",
    "users, animes, target = next(iter(train_dataloader))\n",
    "loss, predictions = run_step(model, loss_fn, users, animes, target)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "grad_norm = 0.0\n",
    "for param in model.parameters():\n",
    "    if param.grad is not None:\n",
    "        grad_norm += param.grad.norm(2).item() ** 2  # L2 norm for each parameter\n",
    "grad_norm = grad_norm ** 0.5  # Square root to get the L2 norm\n",
    "\n",
    "print(\"Gradient Norm:\", grad_norm)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading an existing model\n",
    "\n",
    "It could be useful to start from where we left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from fresh: no models to load\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def get_unique_experiment_name():\n",
    "    return model.__class__.__name__ + \"_\" + model.size()\n",
    "\n",
    "\n",
    "models_dir = \"/home/andreacacioli/Documents/github/MachineLearning/Anime Recommender System (Knime)/models/\"\n",
    "checkpoints = os.listdir(models_dir)\n",
    "unique_name = get_unique_experiment_name()\n",
    "checkpoints = [\n",
    "    f for f in checkpoints if f[: min(len(unique_name), len(f))] == unique_name\n",
    "]\n",
    "if len(checkpoints) == 0:\n",
    "    print(\"Starting from fresh: no models to load\")\n",
    "    epoch = 0\n",
    "else:\n",
    "    checkpoints.sort(key=lambda x: int(x[x.index(\"-\") + 1 : -3]), reverse=True)\n",
    "\n",
    "    epoch = int(checkpoints[0][checkpoints[0].index(\"-\") + 1 : -3])\n",
    "    print(f\"Loading from {models_dir + checkpoints[0]}\")\n",
    "    model.load_state_dict(t.load(models_dir + checkpoints[0], weights_only=True))\n",
    "    print(f\"Loaded epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "\n",
    "We set up a simple training loot that uses the validation and training sets to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrea-cacioli\u001b[0m (\u001b[33mandrea-cacioli-education\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/andreacacioli/Documents/github/MachineLearning/Anime Recommender System (Knime)/wandb/run-20241121_211610-3hh6n1u2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization/runs/3hh6n1u2' target=\"_blank\">sage-fire-12</a></strong> to <a href='https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization' target=\"_blank\">https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization/runs/3hh6n1u2' target=\"_blank\">https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization/runs/3hh6n1u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization/runs/3hh6n1u2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7a0a9c2eb970>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Wandb\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "wandb.init(\n",
    "    project=\"Anime Recommender System - Matrix Factorization\",\n",
    "    config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"emb_size\": model.emb_size,\n",
    "        \"dataset\": dataset.dataset_name\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Best Epoch: 2: Validation Loss: 0.7221423983573914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 87949/140081 [1:10:31<41:48, 20.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 29\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m})\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#Validation Step\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m t\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import copy\n",
    "\n",
    "\n",
    "EVAL_EVERY = 10 # Only running evaluation step every 10 training steps\n",
    "\n",
    "epochs = epoch + 8 # Set this to the number of training epochs you want to perform\n",
    "\n",
    "with t.no_grad(): # To initialize the eval loss before training\n",
    "    model.eval()\n",
    "    us, an, ta = next(iter(validation_dataloader))\n",
    "    loss, _ = run_step(model, loss_fn, us, an, ta)\n",
    "    loss = loss.item()\n",
    "    best_eval_loss = loss\n",
    "    best_epoch = -1\n",
    "    model.train()\n",
    "\n",
    "\n",
    "while epoch < epochs:\n",
    "    i = 0\n",
    "    for users, animes, target in tqdm(train_dataloader):\n",
    "        #Training Step\n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = run_step(model, loss_fn, users, animes, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        wandb.log({\"train_loss\": loss.item()})\n",
    "\n",
    "\n",
    "        if i == 0:\n",
    "            #Validation Step\n",
    "            with t.no_grad():\n",
    "                model.eval()\n",
    "                us, an, ta = next(iter(validation_dataloader))\n",
    "                loss, _ = run_step(model, loss_fn, us, an, ta)\n",
    "                loss = loss.item()\n",
    "                wandb.log({\"eval_loss\": loss})\n",
    "                if loss < best_eval_loss: # Getting the best model\n",
    "                    best_eval_loss = loss\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    best_epoch = epoch\n",
    "                model.train()\n",
    "        i = (i + 1) % EVAL_EVERY\n",
    "\n",
    "    \n",
    "    clear_output()\n",
    "    print(f\"Current Best Epoch: {best_epoch}: Validation Loss: {best_eval_loss}\")\n",
    "    epoch += 1\n",
    "\n",
    "print(f\"Going back to epoch {best_epoch}: validation loss: {best_eval_loss}\")\n",
    "model = best_model\n",
    "epoch = best_epoch\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_loss</td><td>█▃▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▂▁▁▁▂▁▂▂▂▂▁▁▁▂▁</td></tr><tr><td>train_loss</td><td>▇▇█▆▅▆▇▇▄▄▄▂▃▂▂▃▃▂▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_loss</td><td>1.11687</td></tr><tr><td>train_loss</td><td>0.11421</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-fire-12</strong> at: <a href='https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization/runs/3hh6n1u2' target=\"_blank\">https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization/runs/3hh6n1u2</a><br/> View project at: <a href='https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization' target=\"_blank\">https://wandb.ai/andrea-cacioli-education/Anime%20Recommender%20System%20-%20Matrix%20Factorization</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241121_211610-3hh6n1u2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = best_model\n",
    "epoch = best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model\n",
    "\n",
    "As long as we are carrying out the same experiment we should be able to save and load the model.\n",
    "This saves a lot of time and allows us to restart from where we left off the previous time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(\n",
    "    model.state_dict(),\n",
    "    f\"/home/andreacacioli/Documents/github/MachineLearning/Anime Recommender System (Knime)/models/{get_unique_experiment_name()}_epoch-{epoch}.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Iterating over the test set we can see how the model predicts user preferences on unseen user data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40023/40023 [01:32<00:00, 434.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_losses = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with t.no_grad():\n",
    "    model.eval()\n",
    "    for users, animes, target in tqdm(test_dataloader):\n",
    "        loss, prediction_table = run_step(model, loss_fn, users, animes, target)\n",
    "        loss = loss.item()\n",
    "        test_losses.append(loss)\n",
    "\n",
    "        #Only getting predictions we know to be true\n",
    "        mask = target != 0\n",
    "        target = target[mask].tolist()\n",
    "        # prediction table has already been masked\n",
    "        prediction_table = prediction_table.tolist()\n",
    "\n",
    "        y_true += target\n",
    "        y_pred += prediction_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 1.2035735766664812\n",
      "R2 Score: 0.5824502567662821\n",
      "On average the model gets it wrong by 0.8144065496299469 votes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "print(f\"Average test loss: {sum(test_losses) / len(test_losses)}\")\n",
    "print(f\"R2 Score: {r2_score(y_true,y_pred)}\")\n",
    "print(f\"On average the model gets it wrong by {mean_absolute_error(y_true, y_pred)} votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [9, 7, 10, 8, 8, 9, 8, 7, 6, 5]\n",
      "y_pred: [9.028223991394043, 8.072425842285156, 9.172599792480469, 8.585355758666992, 7.19703483581543, 8.742650985717773, 8.74620246887207, 6.316115379333496, 7.385806560516357, 6.583293437957764]\n"
     ]
    }
   ],
   "source": [
    "print(f'y_true: {y_true[:10]}')\n",
    "print(f'y_pred: {y_pred[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.09045026885569918\n",
      "On average the baseline gets it wrong by 1.3748572001654604 votes\n"
     ]
    }
   ],
   "source": [
    "y_pred_baseline = [7] * len(y_pred)\n",
    "\n",
    "print(f\"R2 Score: {r2_score(y_true,y_pred_baseline)}\")\n",
    "print(f\"On average the baseline gets it wrong by {mean_absolute_error(y_true, y_pred_baseline)} votes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
